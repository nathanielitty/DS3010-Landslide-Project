{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeSfuJMmioY6rWc/vDtY1X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suTaMh8LuYxQ","executionInfo":{"status":"ok","timestamp":1709245204243,"user_tz":300,"elapsed":21195,"user":{"displayName":"Matthew Rosenberger","userId":"01586521780888396388"}},"outputId":"60b3369a-341b-4775-9f42-44b26638ce97"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from google.colab import files\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","\n","\n","\n","\n","file_path = '/content/drive/MyDrive/DS3010 Project/Complete-data.csv'\n","df = pd.read_csv(file_path)\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcletvhPueAh","executionInfo":{"status":"ok","timestamp":1709245214163,"user_tz":300,"elapsed":7395,"user":{"displayName":"Matthew Rosenberger","userId":"01586521780888396388"}},"outputId":"0aaaa53b-e049-4e40-84e4-cba7fbb85e03"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["      Landslide  Aspect  Curvature  Earthquake  Elevation  Flow  Lithology  \\\n","0             0       3          3           2          2     2          1   \n","1             0       1          5           2          3     1          1   \n","2             0       3          4           3          2     2          4   \n","3             0       1          3           3          3     5          1   \n","4             0       5          4           2          1     4          1   \n","...         ...     ...        ...         ...        ...   ...        ...   \n","1207          1       4          2           1          4     2          5   \n","1208          1       4          5           1          5     3          5   \n","1209          1       3          4           1          5     2          5   \n","1210          1       2          2           1          3     1          1   \n","1211          1       3          4           1          3     2          1   \n","\n","      NDVI  NDWI  Plan  Precipitation  Profile  Slope  \n","0        4     2     2              3        3      2  \n","1        4     2     5              5        2      2  \n","2        3     2     4              5        2      2  \n","3        2     4     3              5        3      3  \n","4        2     4     3              3        1      4  \n","...    ...   ...   ...            ...      ...    ...  \n","1207     1     5     3              2        4      2  \n","1208     1     5     5              2        1      5  \n","1209     2     3     3              2        2      5  \n","1210     5     1     1              1        3      3  \n","1211     4     1     4              1        2      3  \n","\n","[1212 rows x 13 columns]\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('device:',  device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2CE2by71yKl-","executionInfo":{"status":"ok","timestamp":1709245218309,"user_tz":300,"elapsed":158,"user":{"displayName":"Matthew Rosenberger","userId":"01586521780888396388"}},"outputId":"bd145949-100d-4dd6-ca36-c4c8e76cf9bd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["device: cpu\n"]}]},{"cell_type":"code","source":["features = df.drop('Landslide', axis=1)\n","target = df['Landslide']\n","features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.5, shuffle=True)\n"],"metadata":{"id":"mVkpgMxIup-N","executionInfo":{"status":"ok","timestamp":1709245219839,"user_tz":300,"elapsed":212,"user":{"displayName":"Matthew Rosenberger","userId":"01586521780888396388"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class Net(torch.nn.Module):\n","    def __init__(self, n_feature, n_hidden, n_output):\n","        super(Net, self).__init__()\n","        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n","        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n","\n","    def forward(self, x):\n","        x = F.relu(self.hidden(x))      # activation function for hidden layer\n","        x = self.predict(x)             # linear output\n","        return x"],"metadata":{"id":"v058FC_vysBU","executionInfo":{"status":"ok","timestamp":1709245221584,"user_tz":300,"elapsed":267,"user":{"displayName":"Matthew Rosenberger","userId":"01586521780888396388"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["net = Net(n_feature=12, n_hidden=12, n_output=1)     # define the network\n","print(net)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMcy6In3yyxw","executionInfo":{"status":"ok","timestamp":1709245223433,"user_tz":300,"elapsed":171,"user":{"displayName":"Matthew Rosenberger","userId":"01586521780888396388"}},"outputId":"fd64d65e-c158-4a15-dbf2-4cde2a414472"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Net(\n","  (hidden): Linear(in_features=12, out_features=12, bias=True)\n","  (predict): Linear(in_features=12, out_features=1, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n","loss_func = torch.nn.MSELoss()"],"metadata":{"id":"63g3_ipNSt9m","executionInfo":{"status":"ok","timestamp":1709245229408,"user_tz":300,"elapsed":4974,"user":{"displayName":"Matthew Rosenberger","userId":"01586521780888396388"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def combinedlistsorting(train, prediction):\n","    combined_lists = list(zip(train, prediction))\n","\n","    sorted_combined_lists = sorted(combined_lists, key=lambda x: x[0])\n","\n","    sorted_list1, sorted_list2 = zip(*sorted_combined_lists)\n","    return sorted_list1, sorted_list2\n"],"metadata":{"id":"vV8C7wO5TBtg","executionInfo":{"status":"ok","timestamp":1709245230532,"user_tz":300,"elapsed":161,"user":{"displayName":"Matthew Rosenberger","userId":"01586521780888396388"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","xtrain = torch.tensor(features_train.values, dtype=torch.float32).to(device)\n","ytrain = torch.tensor(target_train.values, dtype=torch.float32).to(device)\n","xtest = torch.tensor(features_test.values, dtype=torch.float32).to(device)\n","ytest = torch.tensor(target_test.values, dtype=torch.float32).to(device)\n","\n","net.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4J47Oj9STJ4E","executionInfo":{"status":"ok","timestamp":1709245232416,"user_tz":300,"elapsed":150,"user":{"displayName":"Matthew Rosenberger","userId":"01586521780888396388"}},"outputId":"20913a20-32fe-492c-a20e-1c0bbee6d67c"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (hidden): Linear(in_features=12, out_features=12, bias=True)\n","  (predict): Linear(in_features=12, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import torch\n","\n","best_loss = float('inf')\n","mse = torch.nn.MSELoss()\n","mae = torch.nn.L1Loss()\n","\n","for t in range(1000):\n","    prediction = net(xtrain)\n","\n","    loss = loss_func(prediction, ytrain)     # compute loss\n","    mse_loss = mse(prediction, ytrain)       # Mean Squared Error\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if t % 5 == 0:\n","        print(f'Epoch [{t}/{1000}], Loss: {loss.item():.4f}, MSE: {mse_loss.item():.4f}')\n","\n","        if loss.item() < best_loss:\n","            best_loss = loss.item()\n","\n","print(f'Best Loss: {best_loss}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vy5c5O3DWpGs","executionInfo":{"status":"ok","timestamp":1709245814542,"user_tz":300,"elapsed":2703,"user":{"displayName":"Matthew Rosenberger","userId":"01586521780888396388"}},"outputId":"033e34b2-bcbd-4f57-fdb1-1a239e4d2ce0"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([606])) that is different to the input size (torch.Size([606, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [0/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [5/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [10/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [15/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [20/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [25/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [30/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [35/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [40/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [45/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [50/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [55/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [60/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [65/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [70/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [75/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [80/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [85/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [90/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [95/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [100/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [105/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [110/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [115/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [120/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [125/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [130/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [135/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [140/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [145/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [150/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [155/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [160/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [165/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [170/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [175/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [180/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [185/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [190/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [195/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [200/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [205/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [210/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [215/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [220/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [225/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [230/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [235/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [240/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [245/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [250/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [255/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [260/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [265/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [270/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [275/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [280/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [285/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [290/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [295/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [300/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [305/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [310/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [315/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [320/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [325/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [330/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [335/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [340/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [345/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [350/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [355/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [360/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [365/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [370/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [375/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [380/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [385/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [390/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [395/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [400/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [405/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [410/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [415/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [420/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [425/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [430/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [435/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [440/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [445/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [450/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [455/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [460/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [465/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [470/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [475/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [480/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [485/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [490/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [495/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [500/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [505/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [510/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [515/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [520/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [525/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [530/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [535/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [540/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [545/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [550/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [555/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [560/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [565/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [570/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [575/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [580/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [585/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [590/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [595/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [600/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [605/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [610/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [615/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [620/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [625/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [630/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [635/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [640/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [645/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [650/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [655/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [660/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [665/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [670/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [675/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [680/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [685/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [690/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [695/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [700/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [705/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [710/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [715/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [720/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [725/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [730/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [735/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [740/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [745/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [750/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [755/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [760/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [765/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [770/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [775/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [780/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [785/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [790/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [795/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [800/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [805/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [810/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [815/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [820/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [825/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [830/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [835/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [840/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [845/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [850/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [855/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [860/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [865/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [870/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [875/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [880/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [885/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [890/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [895/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [900/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [905/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [910/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [915/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [920/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [925/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [930/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [935/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [940/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [945/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [950/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [955/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [960/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [965/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [970/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [975/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [980/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [985/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [990/1000], Loss: 0.2493, MSE: 0.2493\n","Epoch [995/1000], Loss: 0.2493, MSE: 0.2493\n","Best Loss: 0.249302938580513\n"]}]}]}